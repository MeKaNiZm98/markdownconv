"""
Document Analyzer with Microsoft MarkItDown and LLM-based Image Description

This Streamlit application allows users to upload documents (including PDFs) and have their 
contents extracted, analyzed, and optionally enhanced by a Large Language Model (LLM). 
If enabled, embedded images in PDF pages can be individually extracted and described by 
the LLM, integrating figure references seamlessly into the extracted text.

Installation and Requirements:
1. Python 3.8 or newer is recommended.
2. Install Streamlit:
   ```bash
   pip install streamlit
"""

import streamlit as st
import os
from markitdown import MarkItDown
from pathlib import Path
import tempfile
from dotenv import load_dotenv
import requests
from types import SimpleNamespace
import pdfplumber
from PIL import Image
import base64

# Attempt to import OpenAI; if not available, set OpenAI = None
try:
    from openai import OpenAI
except ImportError:
    OpenAI = None

# Load environment variables
load_dotenv()

debug_logs = []
def log_debug(message: str):
    debug_logs.append(message)

# Translation dictionaries
translations = {
    "en": {
        "page_title": "Document Analyzer with Microsoft MarkItDown",
        "app_title": "üìÑ Document Analyzer with Microsoft MarkItDown",
        "app_description": "Upload a PDF or other document to extract text and analyze embedded images using LLM.",
        "file_uploader": "Choose a file",
        "settings_header": "Settings",
        "use_llm_toggle": "Use LLM for Enhanced Analysis",
        "llm_provider_header": "LLM Provider",
        "select_llm_provider": "Select LLM Provider",
        "openai_api_key": "OpenAI API Key",
        "api_key_help": "Your API key will not be stored and is only used for this session",
        "local_llm_url": "Local LLM URL",
        "local_llm_help": "URL for your local LLM server",
        "clear_cache": "Clear Cache",
        "cache_cleared": "Cache cleared!",
        "supported_formats": "Supported Formats:",
        "processing": "Processing document...",
        "analysis_results": "Analysis Results",
        "tab_extracted": "Extracted Content",
        "tab_info": "Document Information",
        "tab_debug": "Debug Logs",
        "download_button": "Download Extracted Content",
        "debug_logs_title": "Debug Logs:",
        "no_debug_logs": "No debug logs available.",
        "error_processing": "Error processing document:",
        "upload_prompt": "üëà Please upload a document using the sidebar to begin analysis",
        "language_selector": "Language / Sprache",
        "figure_text": "Figure",
        "document_language": "Document Language",
        "document_language_help": "Select the main language of the document. The LLM will be informed that other languages may also be present.",
        "auto_detect": "Auto-detect",
        "multilingual_prompt": "This document is primarily in {}, but may contain content in other languages as well.",
        "drag_drop_text": "Drag and drop files here or browse files"
    },
    "de": {
        "page_title": "Dokumentenanalyse mit Microsoft MarkItDown",
        "app_title": "üìÑ Dokumentenanalyse mit Microsoft MarkItDown",
        "app_description": "Laden Sie ein PDF oder anderes Dokument hoch, um Text zu extrahieren und eingebettete Bilder mit LLM zu analysieren.",
        "file_uploader": "Datei ausw√§hlen",
        "settings_header": "Einstellungen",
        "use_llm_toggle": "LLM f√ºr erweiterte Analyse verwenden",
        "llm_provider_header": "LLM-Anbieter",
        "select_llm_provider": "LLM-Anbieter ausw√§hlen",
        "openai_api_key": "OpenAI API-Schl√ºssel",
        "api_key_help": "Ihr API-Schl√ºssel wird nicht gespeichert und nur f√ºr diese Sitzung verwendet",
        "local_llm_url": "Lokale LLM-URL",
        "local_llm_help": "URL f√ºr Ihren lokalen LLM-Server",
        "clear_cache": "Cache leeren",
        "cache_cleared": "Cache geleert!",
        "supported_formats": "Unterst√ºtzte Formate:",
        "processing": "Dokument wird verarbeitet...",
        "analysis_results": "Analyseergebnisse",
        "tab_extracted": "Extrahierter Inhalt",
        "tab_info": "Dokumentinformationen",
        "tab_debug": "Debug-Protokolle",
        "download_button": "Extrahierten Inhalt herunterladen",
        "debug_logs_title": "Debug-Protokolle:",
        "no_debug_logs": "Keine Debug-Protokolle verf√ºgbar.",
        "error_processing": "Fehler bei der Verarbeitung des Dokuments:",
        "upload_prompt": "üëà Bitte laden Sie ein Dokument √ºber die Seitenleiste hoch, um mit der Analyse zu beginnen",
        "language_selector": "Sprache / Language",
        "figure_text": "Abbildung",
        "drag_drop_text": "Dateien hierher ziehen und ablegen oder durchsuchen",
        "extract_images_text": "Extrahiert Text und Bilder und beschreibt Bilder inline, wenn LLM aktiviert ist",
        "document_language": "Dokumentsprache",
        "document_language_help": "W√§hlen Sie die Hauptsprache des Dokuments. Das LLM wird dar√ºber informiert, dass auch andere Sprachen vorhanden sein k√∂nnen.",
        "auto_detect": "Automatisch erkennen",
        "multilingual_prompt": "Dieses Dokument ist haupts√§chlich in {} verfasst, kann aber auch Inhalte in anderen Sprachen enthalten."
    },
    "fr": {
        "page_title": "Analyseur de Documents avec Microsoft MarkItDown",
        "app_title": "üìÑ Analyseur de Documents avec Microsoft MarkItDown",
        "app_description": "T√©l√©chargez un PDF ou un autre document pour extraire du texte et analyser les images int√©gr√©es √† l'aide de LLM.",
        "file_uploader": "Choisir un fichier",
        "settings_header": "Param√®tres",
        "use_llm_toggle": "Utiliser LLM pour une analyse am√©lior√©e",
        "llm_provider_header": "Fournisseur LLM",
        "select_llm_provider": "S√©lectionner le fournisseur LLM",
        "openai_api_key": "Cl√© API OpenAI",
        "api_key_help": "Votre cl√© API ne sera pas stock√©e et n'est utilis√©e que pour cette session",
        "local_llm_url": "URL LLM locale",
        "local_llm_help": "URL pour votre serveur LLM local",
        "clear_cache": "Vider le cache",
        "cache_cleared": "Cache vid√© !",
        "supported_formats": "Formats pris en charge :",
        "processing": "Traitement du document...",
        "analysis_results": "R√©sultats d'analyse",
        "tab_extracted": "Contenu extrait",
        "tab_info": "Informations sur le document",
        "tab_debug": "Journaux de d√©bogage",
        "download_button": "T√©l√©charger le contenu extrait",
        "debug_logs_title": "Journaux de d√©bogage :",
        "no_debug_logs": "Aucun journal de d√©bogage disponible.",
        "error_processing": "Erreur lors du traitement du document :",
        "upload_prompt": "üëà Veuillez t√©l√©charger un document √† l'aide de la barre lat√©rale pour commencer l'analyse",
        "language_selector": "Langue / Sprache",
        "figure_text": "Figure",
        "drag_drop_text": "Glissez-d√©posez des fichiers ici ou parcourez les fichiers",
        "extract_images_text": "Extrai le texte et les images et d√©crit les images en ligne si LLM est activ√©",
        "document_language": "Langue du document",
        "document_language_help": "S√©lectionnez la langue principale du document. Le LLM sera inform√© que d'autres langues peuvent √©galement √™tre pr√©sentes.",
        "auto_detect": "D√©tection automatique",
        "multilingual_prompt": "Ce document est principalement en {}, mais peut √©galement contenir du contenu dans d'autres langues."
    },
    "es": {
        "page_title": "Analizador de Documentos con Microsoft MarkItDown",
        "app_title": "üìÑ Analizador de Documentos con Microsoft MarkItDown",
        "app_description": "Suba un PDF u otro documento para extraer texto y analizar im√°genes incrustadas usando LLM.",
        "file_uploader": "Elegir un archivo",
        "settings_header": "Configuraci√≥n",
        "use_llm_toggle": "Usar LLM para an√°lisis mejorado",
        "llm_provider_header": "Proveedor de LLM",
        "select_llm_provider": "Seleccionar proveedor de LLM",
        "openai_api_key": "Clave API de OpenAI",
        "api_key_help": "Su clave API no se almacenar√° y solo se usa para esta sesi√≥n",
        "local_llm_url": "URL de LLM local",
        "local_llm_help": "URL para su servidor LLM local",
        "clear_cache": "Limpiar cach√©",
        "cache_cleared": "¬°Cach√© limpiada!",
        "supported_formats": "Formatos soportados:",
        "processing": "Procesando documento...",
        "analysis_results": "Resultados del an√°lisis",
        "tab_extracted": "Contenido extra√≠do",
        "tab_info": "Informaci√≥n del documento",
        "tab_debug": "Registros de depuraci√≥n",
        "download_button": "Descargar contenido extra√≠do",
        "debug_logs_title": "Registros de depuraci√≥n:",
        "no_debug_logs": "No hay registros de depuraci√≥n disponibles.",
        "error_processing": "Error al procesar el documento:",
        "upload_prompt": "üëà Por favor, suba un documento usando la barra lateral para comenzar el an√°lisis",
        "language_selector": "Idioma / Sprache",
        "figure_text": "Figura",
        "drag_drop_text": "Arrastre y solte archivos aqu√≠ o explore archivos",
        "extract_images_text": "Extrae texto e im√°genes y describe im√°genes en l√≠nea si LLM est√° habilitado",
        "document_language": "Idioma del documento",
        "document_language_help": "Selecione el idioma principal del documento. Se informar√° al LLM que tambi√©n pueden estar presentes otros idiomas.",
        "auto_detect": "Detecci√≥n autom√°tica",
        "multilingual_prompt": "Este documento est√° principalmente en {}, pero tambi√©n puede contener contenido en otros idiomas."
    },
    "it": {
        "page_title": "Analizzatore di Documenti con Microsoft MarkItDown",
        "app_title": "üìÑ Analizzatore di Documenti con Microsoft MarkItDown",
        "app_description": "Carica un PDF o un altro documento per estrarre testo e analizzare immagini incorporate utilizzando LLM.",
        "file_uploader": "Scegli un file",
        "settings_header": "Impostazioni",
        "use_llm_toggle": "Usa LLM per analisi avanzata",
        "llm_provider_header": "Provider LLM",
        "select_llm_provider": "Seleziona provider LLM",
        "openai_api_key": "Chiave API OpenAI",
        "api_key_help": "La tua chiave API non verr√† memorizzata e viene utilizzata solo per questa sessione",
        "local_llm_url": "URL LLM locale",
        "local_llm_help": "URL per il tuo server LLM locale",
        "clear_cache": "Cancella cache",
        "cache_cleared": "Cache cancellata!",
        "supported_formats": "Formati supportati:",
        "processing": "Elaborazione documento...",
        "analysis_results": "Risultati dell'analisi",
        "tab_extracted": "Contenuto estratto",
        "tab_info": "Informazioni documento",
        "tab_debug": "Log di debug",
        "download_button": "Scarica contenuto estratto",
        "debug_logs_title": "Log di debug:",
        "no_debug_logs": "Nessun log di debug disponibile.",
        "error_processing": "Errore durante l'elaborazione del documento:",
        "upload_prompt": "üëà Carica un documento utilizzando la barra laterale per iniziare l'analisi",
        "language_selector": "Lingua / Sprache",
        "figure_text": "Figura",
        "drag_drop_text": "Trascina e rilascia i file qui o sfoglia i file",
        "extract_images_text": "Estrae testo e immagini e descrive le immagini in linea se LLM √® abilitato",
        "document_language": "Lingua del documento",
        "document_language_help": "Seleziona la lingua principale del documento. Il LLM sar√† informato che potrebbero essere presenti anche altre lingue.",
        "auto_detect": "Rilevamento automatico",
        "multilingual_prompt": "Questo documento √® principalmente in {}, ma pu√≤ contenere anche contenuti in altre lingue."
    },
    "nl": {
        "page_title": "Documentanalyse met Microsoft MarkItDown",
        "app_title": "üìÑ Documentanalyse met Microsoft MarkItDown",
        "app_description": "Upload een PDF of ander document om tekst te extraheren en ingesloten afbeeldingen te analyseren met behulp van LLM.",
        "file_uploader": "Kies een bestand",
        "settings_header": "Instellingen",
        "use_llm_toggle": "Gebruik LLM voor verbeterde analyse",
        "llm_provider_header": "LLM-provider",
        "select_llm_provider": "Selecteer LLM-provider",
        "openai_api_key": "OpenAI API-sleutel",
        "api_key_help": "Uw API-sleutel wordt niet opgeslagen en wordt alleen gebruikt voor deze sessie",
        "local_llm_url": "Lokale LLM-URL",
        "local_llm_help": "URL voor uw lokale LLM-server",
        "clear_cache": "Cache wissen",
        "cache_cleared": "Cache gewist!",
        "supported_formats": "Ondersteunde formaten:",
        "processing": "Document verwerken...",
        "analysis_results": "Analyseresultaten",
        "tab_extracted": "Ge√´xtraheerde inhoud",
        "tab_info": "Documentinformatie",
        "tab_debug": "Debug-logboeken",
        "download_button": "Download ge√´xtraheerde inhoud",
        "debug_logs_title": "Debug-logboeken:",
        "no_debug_logs": "Geen debug-logboeken beschikbaar.",
        "error_processing": "Fout bij het verwerken van document:",
        "upload_prompt": "üëà Upload een document via de zijbalk om de analyse te starten",
        "language_selector": "Taal / Sprache",
        "figure_text": "Figuur",
        "drag_drop_text": "Sleep bestanden hierheen of blader door bestanden",
        "extract_images_text": "Extraheert tekst en afbeeldingen en beschrijft afbeeldingen inline als LLM is ingeschakeld",
        "document_language": "Documenttaal",
        "document_language_help": "Selecteer de hoofdtaal van het document. De LLM wordt ge√Ønformeerd dat er ook andere talen aanwezig kunnen zijn.",
        "auto_detect": "Automatisch detecteren",
        "multilingual_prompt": "Dit document is voornamelijk in {}, maar kan ook inhoud in andere talen bevatten."
    },
    "pt": {
        "page_title": "Analisador de Documentos com Microsoft MarkItDown",
        "app_title": "üìÑ Analisador de Documentos com Microsoft MarkItDown",
        "app_description": "Carregue um PDF ou outro documento para extrair texto e analisar imagens incorporadas usando LLM.",
        "file_uploader": "Escolher um arquivo",
        "settings_header": "Configura√ß√µes",
        "use_llm_toggle": "Usar LLM para an√°lise aprimorada",
        "llm_provider_header": "Provedor de LLM",
        "select_llm_provider": "Selecionar provedor de LLM",
        "openai_api_key": "Chave API OpenAI",
        "api_key_help": "Sua chave API n√£o ser√° armazenada e √© usada apenas para esta sess√£o",
        "local_llm_url": "URL LLM local",
        "local_llm_help": "URL para seu servidor LLM local",
        "clear_cache": "Limpar cache",
        "cache_cleared": "Cache limpo!",
        "supported_formats": "Formatos suportados:",
        "processing": "Processando documento...",
        "analysis_results": "Resultados da an√°lise",
        "tab_extracted": "Conte√∫do extra√≠do",
        "tab_info": "Informa√ß√µes do documento",
        "tab_debug": "Registros de depura√ß√£o",
        "download_button": "Baixar conte√∫do extra√≠do",
        "debug_logs_title": "Registros de depura√ß√£o:",
        "no_debug_logs": "Nenhum registro de depura√ß√£o dispon√≠vel.",
        "error_processing": "Erro ao processar o documento:",
        "upload_prompt": "üëà Por favor, carregue um documento usando a barra lateral para iniciar a an√°lise",
        "language_selector": "Idioma / Sprache",
        "figure_text": "Figura",
        "drag_drop_text": "Arraste e solte arquivos aqui ou navegue pelos arquivos",
        "extract_images_text": "Extrai texto e imagens e descreve imagens em linha se o LLM estiver ativado",
        "document_language": "Idioma do documento",
        "document_language_help": "Selecione o idioma principal do documento. O LLM ser√° informado que outros idiomas tamb√©m podem estar presentes.",
        "auto_detect": "Detec√ß√£o autom√°tica",
        "multilingual_prompt": "Este documento √© principalmente em {}, mas tamb√©m pode conter conte√∫do em outros idiomas."
    },
    "ru": {
        "page_title": "–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å Microsoft MarkItDown",
        "app_title": "üìÑ –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å Microsoft MarkItDown",
        "app_description": "–ó–∞–≥—Ä—É–∑–∏—Ç–µ PDF –∏–ª–∏ –¥—Ä—É–≥–æ–π –¥–æ–∫—É–º–µ–Ω—Ç –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –∏ –∞–Ω–∞–ª–∏–∑–∞ –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –ø–æ–º–æ—â—å—é LLM.",
        "file_uploader": "–í—ã–±—Ä–∞—Ç—å —Ñ–∞–π–ª",
        "settings_header": "–ù–∞—Å—Ç—Ä–æ–π–∫–∏",
        "use_llm_toggle": "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å LLM –¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞",
        "llm_provider_header": "–ü–æ—Å—Ç–∞–≤—â–∏–∫ LLM",
        "select_llm_provider": "–í—ã–±—Ä–∞—Ç—å –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞ LLM",
        "openai_api_key": "–ö–ª—é—á API OpenAI",
        "api_key_help": "–í–∞—à –∫–ª—é—á API –Ω–µ –±—É–¥–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –¥–ª—è —ç—Ç–æ–π —Å–µ—Å—Å–∏–∏",
        "local_llm_url": "–õ–æ–∫–∞–ª—å–Ω—ã–π URL LLM",
        "local_llm_help": "URL –¥–ª—è –≤–∞—à–µ–≥–æ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞ LLM",
        "clear_cache": "–û—á–∏—Å—Ç–∏—Ç—å –∫—ç—à",
        "cache_cleared": "–ö—ç—à –æ—á–∏—â–µ–Ω!",
        "supported_formats": "–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã:",
        "processing": "–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞...",
        "analysis_results": "–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞",
        "tab_extracted": "–ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç",
        "tab_info": "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–æ–∫—É–º–µ–Ω—Ç–µ",
        "tab_debug": "–ñ—É—Ä–Ω–∞–ª—ã –æ—Ç–ª–∞–¥–∫–∏",
        "download_button": "–°–∫–∞—á–∞—Ç—å –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç",
        "debug_logs_title": "–ñ—É—Ä–Ω–∞–ª—ã –æ—Ç–ª–∞–¥–∫–∏:",
        "no_debug_logs": "–ñ—É—Ä–Ω–∞–ª—ã –æ—Ç–ª–∞–¥–∫–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã.",
        "error_processing": "–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞:",
        "upload_prompt": "üëà –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç —Å –ø–æ–º–æ—â—å—é –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏, —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å –∞–Ω–∞–ª–∏–∑",
        "language_selector": "–Ø–∑—ã–∫ / Sprache",
        "figure_text": "–†–∏—Å—É–Ω–æ–∫",
        "drag_drop_text": "–ü–µ—Ä–µ—Ç–∞—â–∏—Ç–µ —Ñ–∞–π–ª—ã —Å—é–¥–∞ –∏–ª–∏ –ø—Ä–æ—Å–º–æ—Ç—Ä–∏—Ç–µ —Ñ–∞–π–ª—ã",
        "extract_images_text": "–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –æ–ø–∏—Å—ã–≤–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ —Ç–µ–∫—Å—Ç–µ, –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω LLM",
        "document_language": "–Ø–∑—ã–∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞",
        "document_language_help": "–í—ã–±–µ—Ä–∏—Ç–µ –æ—Å–Ω–æ–≤–Ω–æ–π —è–∑—ã–∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞. LLM –±—É–¥–µ—Ç –ø—Ä–æ–∏–Ω—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω –æ —Ç–æ–º, —á—Ç–æ –º–æ–≥—É—Ç –ø—Ä–∏—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –∏ –¥—Ä—É–≥–∏–µ —è–∑—ã–∫–∏.",
        "auto_detect": "–ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ",
        "multilingual_prompt": "–≠—Ç–æ—Ç –¥–æ–∫—É–º–µ–Ω—Ç –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –Ω–∞ {}, –Ω–æ —Ç–∞–∫–∂–µ –º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç –Ω–∞ –¥—Ä—É–≥–∏—Ö —è–∑—ã–∫–∞—Ö."
    },
    "zh": {
        "page_title": "Microsoft MarkItDown ÊñáÊ°£ÂàÜÊûêÂô®",
        "app_title": "üìÑ Microsoft MarkItDown ÊñáÊ°£ÂàÜÊûêÂô®",
        "app_description": "‰∏ä‰º† PDF ÊàñÂÖ∂‰ªñÊñáÊ°£‰ª•ÊèêÂèñÊñáÊú¨Âπ∂‰ΩøÁî® LLM ÂàÜÊûêÂµåÂÖ•ÁöÑÂõæÂÉè„ÄÇ",
        "file_uploader": "ÈÄâÊã©Êñá‰ª∂",
        "settings_header": "ËÆæÁΩÆ",
        "use_llm_toggle": "‰ΩøÁî® LLM ËøõË°åÂ¢ûÂº∫ÂàÜÊûê",
        "llm_provider_header": "LLM Êèê‰æõÂïÜ",
        "select_llm_provider": "ÈÄâÊã© LLM Êèê‰æõÂïÜ",
        "openai_api_key": "OpenAI API ÂØÜÈí•",
        "api_key_help": "ÊÇ®ÁöÑ API ÂØÜÈí•‰∏ç‰ºöË¢´Â≠òÂÇ®Ôºå‰ªÖÁî®‰∫éÊ≠§‰ºöËØù",
        "local_llm_url": "Êú¨Âú∞ LLM URL",
        "local_llm_help": "ÊÇ®ÁöÑÊú¨Âú∞ LLM ÊúçÂä°Âô®ÁöÑ URL",
        "clear_cache": "Ê∏ÖÈô§ÁºìÂ≠ò",
        "cache_cleared": "ÁºìÂ≠òÂ∑≤Ê∏ÖÈô§ÔºÅ",
        "supported_formats": "ÊîØÊåÅÁöÑÊ†ºÂºèÔºö",
        "processing": "Ê≠£Âú®Â§ÑÁêÜÊñáÊ°£...",
        "analysis_results": "ÂàÜÊûêÁªìÊûú",
        "tab_extracted": "ÊèêÂèñÁöÑÂÜÖÂÆπ",
        "tab_info": "ÊñáÊ°£‰ø°ÊÅØ",
        "tab_debug": "Ë∞ÉËØïÊó•Âøó",
        "download_button": "‰∏ãËΩΩÊèêÂèñÁöÑÂÜÖÂÆπ",
        "debug_logs_title": "Ë∞ÉËØïÊó•ÂøóÔºö",
        "no_debug_logs": "Ê≤°ÊúâÂèØÁî®ÁöÑË∞ÉËØïÊó•Âøó„ÄÇ",
        "error_processing": "Â§ÑÁêÜÊñáÊ°£Êó∂Âá∫ÈîôÔºö",
        "upload_prompt": "üëà ËØ∑‰ΩøÁî®‰æßËæπÊ†è‰∏ä‰º†ÊñáÊ°£‰ª•ÂºÄÂßãÂàÜÊûê",
        "language_selector": "ËØ≠Ë®Ä / Sprache",
        "figure_text": "Âõæ",
        "drag_drop_text": "Â∞ÜÊñá‰ª∂ÊãñÊîæÂà∞Ê≠§Â§ÑÊàñÊµèËßàÊñá‰ª∂",
        "extract_images_text": "ÊèêÂèñÊñáÊú¨ÂíåÂõæÂÉèÔºåÂ¶ÇÊûúÂêØÁî®‰∫Ü LLMÔºåÂàôÂÜÖËÅîÊèèËø∞ÂõæÂÉè",
        "document_language": "ÊñáÊ°£ËØ≠Ë®Ä",
        "document_language_help": "ÈÄâÊã©ÊñáÊ°£ÁöÑ‰∏ªË¶ÅËØ≠Ë®Ä„ÄÇLLM Â∞ÜË¢´ÂëäÁü•ÂèØËÉΩËøòÂ≠òÂú®ÂÖ∂‰ªñËØ≠Ë®Ä„ÄÇ",
        "auto_detect": "Ëá™Âä®Ê£ÄÊµã",
        "multilingual_prompt": "Ê≠§ÊñáÊ°£‰∏ªË¶Å‰ΩøÁî® {}Ôºå‰ΩÜ‰πüÂèØËÉΩÂåÖÂê´ÂÖ∂‰ªñËØ≠Ë®ÄÁöÑÂÜÖÂÆπ„ÄÇ"
    },
    "ja": {
        "page_title": "Microsoft MarkItDown „Éâ„Ç≠„É•„É°„É≥„ÉàÂàÜÊûê„ÉÑ„Éº„É´",
        "app_title": "üìÑ Microsoft MarkItDown „Éâ„Ç≠„É•„É°„É≥„ÉàÂàÜÊûê„ÉÑ„Éº„É´",
        "app_description": "PDF„ÇÑ„Åù„ÅÆ‰ªñ„ÅÆ„Éâ„Ç≠„É•„É°„É≥„Éà„Çí„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ„Åó„Å¶„ÄÅ„ÉÜ„Ç≠„Çπ„Éà„ÇíÊäΩÂá∫„Åó„ÄÅLLM„Çí‰ΩøÁî®„Åó„Å¶Âüã„ÇÅËæº„ÅøÁîªÂÉè„ÇíÂàÜÊûê„Åó„Åæ„Åô„ÄÇ",
        "file_uploader": "„Éï„Ç°„Ç§„É´„ÇíÈÅ∏Êäû",
        "settings_header": "Ë®≠ÂÆö",
        "use_llm_toggle": "Êã°ÂºµÂàÜÊûê„Å´LLM„Çí‰ΩøÁî®",
        "llm_provider_header": "LLM„Éó„É≠„Éê„Ç§„ÉÄ„Éº",
        "select_llm_provider": "LLM„Éó„É≠„Éê„Ç§„ÉÄ„Éº„ÇíÈÅ∏Êäû",
        "openai_api_key": "OpenAI API„Ç≠„Éº",
        "api_key_help": "API„Ç≠„Éº„ÅØ‰øùÂ≠ò„Åï„Çå„Åö„ÄÅ„Åì„ÅÆ„Çª„ÉÉ„Ç∑„Éß„É≥„Åß„ÅÆ„Åø‰ΩøÁî®„Åï„Çå„Åæ„Åô",
        "local_llm_url": "„É≠„Éº„Ç´„É´LLM URL",
        "local_llm_help": "„É≠„Éº„Ç´„É´LLM„Çµ„Éº„Éê„Éº„ÅÆURL",
        "clear_cache": "„Ç≠„É£„ÉÉ„Ç∑„É•„Çí„ÇØ„É™„Ç¢",
        "cache_cleared": "„Ç≠„É£„ÉÉ„Ç∑„É•„Åå„ÇØ„É™„Ç¢„Åï„Çå„Åæ„Åó„ÅüÔºÅ",
        "supported_formats": "„Çµ„Éù„Éº„Éà„Åï„Çå„Å¶„ÅÑ„ÇãÂΩ¢ÂºèÔºö",
        "processing": "„Éâ„Ç≠„É•„É°„É≥„Éà„ÇíÂá¶ÁêÜ‰∏≠...",
        "analysis_results": "ÂàÜÊûêÁµêÊûú",
        "tab_extracted": "ÊäΩÂá∫„Åï„Çå„Åü„Ç≥„É≥„ÉÜ„É≥„ÉÑ",
        "tab_info": "„Éâ„Ç≠„É•„É°„É≥„ÉàÊÉÖÂ†±",
        "tab_debug": "„Éá„Éê„ÉÉ„Ç∞„É≠„Ç∞",
        "download_button": "ÊäΩÂá∫„Åï„Çå„Åü„Ç≥„É≥„ÉÜ„É≥„ÉÑ„Çí„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ",
        "debug_logs_title": "„Éá„Éê„ÉÉ„Ç∞„É≠„Ç∞Ôºö",
        "no_debug_logs": "Âà©Áî®ÂèØËÉΩ„Å™„Éá„Éê„ÉÉ„Ç∞„É≠„Ç∞„ÅØ„ÅÇ„Çä„Åæ„Åõ„Çì„ÄÇ",
        "error_processing": "„Éâ„Ç≠„É•„É°„É≥„Éà„ÅÆÂá¶ÁêÜ‰∏≠„Å´„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„ÅüÔºö",
        "upload_prompt": "üëà „Çµ„Ç§„Éâ„Éê„Éº„Çí‰ΩøÁî®„Åó„Å¶„Éâ„Ç≠„É•„É°„É≥„Éà„Çí„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ„Åó„ÄÅÂàÜÊûê„ÇíÈñãÂßã„Åó„Å¶„Åè„Å†„Åï„ÅÑ",
        "language_selector": "Ë®ÄË™û / Sprache",
        "figure_text": "Âõ≥",
        "drag_drop_text": "„Éï„Ç°„Ç§„É´„Çí„Åì„Åì„Å´„Éâ„É©„ÉÉ„Ç∞ÔºÜ„Éâ„É≠„ÉÉ„Éó„Åô„Çã„Åã„ÄÅ„Éï„Ç°„Ç§„É´„ÇíÂèÇÁÖß",
        "extract_images_text": "„ÉÜ„Ç≠„Çπ„Éà„Å®ÁîªÂÉè„ÇíÊäΩÂá∫„Åó„ÄÅLLM„ÅåÊúâÂäπ„Å™Â†¥Âêà„ÅØÁîªÂÉè„Çí„Ç§„É≥„É©„Ç§„É≥„ÅßË™¨Êòé„Åó„Åæ„Åô",
        "document_language": "„Éâ„Ç≠„É•„É°„É≥„ÉàË®ÄË™û",
        "document_language_help": "„Éâ„Ç≠„É•„É°„É≥„Éà„ÅÆ‰∏ªË¶ÅË®ÄË™û„ÇíÈÅ∏Êäû„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇLLM„Å´„ÅØ‰ªñ„ÅÆË®ÄË™û„ÇÇÂ≠òÂú®„Åô„ÇãÂèØËÉΩÊÄß„Åå„ÅÇ„Çã„Åì„Å®„ÅåÈÄöÁü•„Åï„Çå„Åæ„Åô„ÄÇ",
        "auto_detect": "Ëá™ÂãïÊ§úÂá∫",
        "multilingual_prompt": "„Åì„ÅÆ„Éâ„Ç≠„É•„É°„É≥„Éà„ÅØ‰∏ª„Å´{}„ÅßÊõ∏„Åã„Çå„Å¶„ÅÑ„Åæ„Åô„Åå„ÄÅ‰ªñ„ÅÆË®ÄË™û„ÅÆ„Ç≥„É≥„ÉÜ„É≥„ÉÑ„ÇÇÂê´„Åæ„Çå„Å¶„ÅÑ„ÇãÂèØËÉΩÊÄß„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ"
    }
}

class LocalLLMClient:
    def __init__(self, base_url="http://127.0.0.1:1234/v1/chat/completions"):
        self.base_url = base_url
        self.chat = self.Chat(self.base_url)

    class Chat:
        def __init__(self, base_url):
            self.base_url = base_url
            self.completions = LocalLLMClient.Chat.Completions(self.base_url)

        class Completions:
            def __init__(self, base_url):
                self.base_url = base_url

            def create(self, model, messages, temperature=0.7, max_tokens=-1, stream=False):
                log_debug("Preparing to send request to local LLM...")
                payload_size = 0
                for m in messages:
                    if isinstance(m.get("content"), list):
                        for c in m["content"]:
                            if c.get("type") == "image_url" and "data:image" in c["image_url"]["url"]:
                                image_data = c["image_url"]["url"].split(",")[1]
                                payload_size = len(image_data)
                                if payload_size > 3_000_000:
                                    log_debug("Image is too large to process with LLM.")
                                    return self._convert_to_objects({
                                        "choices": [{
                                            "message": {
                                                "role": "assistant",
                                                "content": "Image too large to process."
                                            }
                                        }]
                                    })

                payload = {
                    "model": model,
                    "messages": messages,
                    "temperature": temperature,
                    "max_tokens": max_tokens,
                    "stream": stream
                }
                log_debug(f"Request Payload: {payload}")
                try:
                    response = requests.post(self.base_url, json=payload, timeout=60)
                    log_debug(f"Request sent to {self.base_url}. HTTP status: {response.status_code}")
                    if response.status_code != 200:
                        log_debug(f"Non-200 status code: {response.status_code}")
                    data = response.json()
                    log_debug(f"Response JSON from LLM: {data}")
                    return self._convert_to_objects(data)
                except requests.Timeout:
                    log_debug("LLM request timed out.")
                    return self._convert_to_objects({
                        "choices": [{
                            "message": {
                                "role": "assistant",
                                "content": "The LLM request timed out."
                            }
                        }]
                    })
                except Exception as e:
                    log_debug(f"Error making LLM request: {str(e)}")
                    raise e

            def _convert_to_objects(self, data):
                def dict_to_namespace(d):
                    if isinstance(d, dict):
                        for k, v in d.items():
                            d[k] = dict_to_namespace(v)
                        return SimpleNamespace(**d)
                    elif isinstance(d, list):
                        return [dict_to_namespace(x) for x in d]
                    else:
                        return d
                return dict_to_namespace(data)

def clear_cache():
    if os.path.exists(".cache"):
        for file in os.listdir(".cache"):
            os.remove(os.path.join(".cache", file))
    st.cache_data.clear()
    log_debug("Cache cleared.")

def image_to_data_uri(pil_img):
    buffered = tempfile.TemporaryFile()
    pil_img.save(buffered, format="PNG")
    buffered.seek(0)
    img_str = base64.b64encode(buffered.read()).decode("utf-8")
    return f"data:image/png;base64,{img_str}"

def describe_image_with_llm(llm_client, llm_model, pil_img, doc_lang="auto", ui_lang="en"):
    with tempfile.TemporaryFile() as buffered:
        pil_img.save(buffered, format="PNG")
        buffered.seek(0)
        img_str = base64.b64encode(buffered.read()).decode("utf-8")
    
    data_uri = f"data:image/png;base64,{img_str}"
    
    # Sprachhinweis f√ºr das LLM hinzuf√ºgen
    prompt_text = "Describe this image in detail:"
    
    if doc_lang != "auto":
        # Bei doc_lang="auto" verwenden wir Englisch als UI-Sprache
        t = translations["en"] if doc_lang == "auto" else translations[ui_lang]
        language_name = {"de": "German", "en": "English", "fr": "French", "es": "Spanish", 
                         "it": "Italian", "nl": "Dutch", "pt": "Portuguese", 
                         "ru": "Russian", "zh": "Chinese", "ja": "Japanese"}.get(doc_lang, doc_lang)
        
        if doc_lang != "auto":
            multilingual_hint = t["multilingual_prompt"].format(language_name)
            prompt_text = f"{prompt_text}\n{multilingual_hint}"

    messages = [
        {
            "role": "user",
            "content": [
                {"type": "text", "text": prompt_text},
                {
                    "type": "image_url",
                    "image_url": {"url": data_uri}
                }
            ]
        }
    ]
    response = llm_client.chat.completions.create(model=llm_model, messages=messages)
    return response.choices[0].message.content.strip()

def process_pdf_with_images_and_text(md, tmp_path, llm_client, llm_model, ui_lang="de", doc_lang="auto"):
    log_debug("Extracting text and images from PDF using pdfplumber.")
    text_pages = []
    figure_counter = 1
    figure_text = translations[ui_lang]["figure_text"]

    with pdfplumber.open(tmp_path) as pdf:
        for page_num, page in enumerate(pdf.pages, start=1):
            # Extract text
            text = page.extract_text() or ""
            lines = text.split('\n')
            words = page.extract_words()

            # Approximate line positions
            line_positions = []
            for ln in lines:
                ln_words = [w for w in words if w['text'] in ln]
                if ln_words:
                    avg_y = sum(w['top'] for w in ln_words) / len(ln_words)
                else:
                    avg_y = None
                line_positions.append((ln, avg_y))

            # Extract images from the page
            # page.images returns a list of image dictionaries with keys: x0, y0, x1, y1
            figs = []
            page_img = page.to_image(resolution=150)
            pil_page_img = page_img.original  # Get the underlying PIL image

            for im in page.images:
                x0, y0, x1, y1 = im['x0'], im['y0'], im['x1'], im['y1']
                # Crop the PIL image at the bounding box of the image
                cropped = pil_page_img.crop((x0, y0, x1, y1))
                
                # Describe the image with LLM
                # Dokumentsprache an LLM weitergeben
                fig_desc = describe_image_with_llm(llm_client, llm_model, cropped, doc_lang, ui_lang)
                fig_y_mid = y0 + (y1 - y0) / 2.0
                figs.append((fig_y_mid, f"{figure_text} {figure_counter}: {fig_desc}"))
                figure_counter += 1
            
            figs.sort(key=lambda f: f[0])

            # Integrate figures into text output
            output_lines = []
            fig_idx = 0
            for (ln, avg_y) in line_positions:
                output_lines.append(ln)
                while fig_idx < len(figs):
                    fig_y, fig_text = figs[fig_idx]
                    if avg_y is not None and fig_y >= avg_y:
                        output_lines.append(fig_text)
                        fig_idx += 1
                    else:
                        break

            # If any figures remain unmatched, place them at the end
            while fig_idx < len(figs):
                output_lines.append(figs[fig_idx][1])
                fig_idx += 1

            page_output = "\n".join(output_lines)
            text_pages.append(f"--- Page {page_num} ---\n{page_output}")

    return "\n\n".join(text_pages)

def process_document(uploaded_file, use_llm=False, llm_provider="Local", custom_api_key=None, local_llm_url=None, ui_lang="de", doc_lang="auto"):
    with tempfile.NamedTemporaryFile(delete=False, suffix=Path(uploaded_file.name).suffix) as tmp_file:
        tmp_file.write(uploaded_file.getvalue())
        tmp_path = tmp_file.name

    try:
        if use_llm:
            if llm_provider == "OpenAI":
                if OpenAI is None:
                    raise RuntimeError("OpenAI library not installed.")
                api_key = custom_api_key or os.getenv('OPENAI_API_KEY')
                if not api_key:
                    raise ValueError("OpenAI API key is required.")
                log_debug("Using OpenAI API client.")
                client = OpenAI(api_key=api_key)
                md = MarkItDown(llm_client=client, llm_model="gpt-4o")
                llm_client = client
                llm_model = "gpt-4o"
            else:
                log_debug("Using Local LLM client.")
                llm_client = LocalLLMClient(base_url=local_llm_url or "http://127.0.0.1:1234/v1/chat/completions")
                llm_model = "llama-3.1-unhinged-vision-8b"
                md = MarkItDown(llm_client=llm_client, llm_model=llm_model)
        else:
            log_debug("Not using LLM.")
            md = MarkItDown()
            llm_client = None
            llm_model = None

        extension = Path(uploaded_file.name).suffix.lower()
        # If PDF and LLM is enabled, do the image+text extraction via pdfplumber
        if extension == ".pdf" and use_llm:
            text_content = process_pdf_with_images_and_text(md, tmp_path, llm_client, llm_model, ui_lang, doc_lang)
        else:
            # Otherwise, just convert normally
            log_debug(f"Converting file with MarkItDown: {tmp_path}")
            result = md.convert(tmp_path)
            text_content = result.text_content.strip() if result and result.text_content else ""

        return text_content
    except Exception as e:
        log_debug(f"Error during document processing: {str(e)}")
        raise e
    finally:
        os.unlink(tmp_path)
        log_debug(f"Temporary file {tmp_path} removed.")

def main():
    # Initialize session state for language selection
    if 'language' not in st.session_state:
        st.session_state.language = "de"  # Default to German
    
    # Get current language
    lang = st.session_state.language
    t = translations[lang]
    
    st.set_page_config(
        page_title=t["page_title"],
        page_icon="üìÑ",
        layout="wide"
    )
    
    with st.sidebar:
        # Sprachauswahl ganz oben in der Seitenleiste platzieren
        lang_option = st.selectbox(
            t["language_selector"],
            options=["üá©üá™ Deutsch", "üá¨üáß English", "üá´üá∑ Fran√ßais", "üá™üá∏ Espa√±ol", "üáÆüáπ Italiano", 
                    "üá≥üá± Nederlands", "üáµüáπ Portugu√™s", "üá∑üá∫ –†—É—Å—Å–∫–∏–π", "üá®üá≥ ‰∏≠Êñá", "üáØüáµ Êó•Êú¨Ë™û"],
            index=0 if lang == "de" else 1 if lang == "en" else 2 if lang == "fr" else 
                  3 if lang == "es" else 4 if lang == "it" else 5 if lang == "nl" else
                  6 if lang == "pt" else 7 if lang == "ru" else 8 if lang == "zh" else 9
        )
        
        # Sprache basierend auf Auswahl aktualisieren
        if lang_option == "üá¨üáß English" and lang != "en":
            st.session_state.language = "en"
            st.experimental_rerun()
        elif lang_option == "üá©üá™ Deutsch" and lang != "de":
            st.session_state.language = "de"
            st.experimental_rerun()
        elif lang_option == "üá´üá∑ Fran√ßais" and lang != "fr":
            st.session_state.language = "fr"
            st.experimental_rerun()
        elif lang_option == "üá™üá∏ Espa√±ol" and lang != "es":
            st.session_state.language = "es"
            st.experimental_rerun()
        elif lang_option == "üáÆüáπ Italiano" and lang != "it":
            st.session_state.language = "it"
            st.experimental_rerun()
        elif lang_option == "üá≥üá± Nederlands" and lang != "nl":
            st.session_state.language = "nl"
            st.experimental_rerun()
        elif lang_option == "üáµüáπ Portugu√™s" and lang != "pt":
            st.session_state.language = "pt"
            st.experimental_rerun()
        elif lang_option == "üá∑üá∫ –†—É—Å—Å–∫–∏–π" and lang != "ru":
            st.session_state.language = "ru"
            st.experimental_rerun()
        elif lang_option == "üá®üá≥ ‰∏≠Êñá" and lang != "zh":
            st.session_state.language = "zh"
            st.experimental_rerun()
        elif lang_option == "üáØüáµ Êó•Êú¨Ë™û" and lang != "ja":
            st.session_state.language = "ja"
            st.experimental_rerun()
            
        # Titel und Beschreibung nach der Sprachauswahl
        st.title(t["app_title"])
        st.write(t["app_description"])
        
        uploaded_file = st.file_uploader(
            t["file_uploader"], 
            type=['pdf', 'pptx', 'docx', 'xlsx', 'jpg', 'png', 'mp3', 'wav', 'html', 'csv', 'json', 'xml'],
            label_visibility="visible",
            accept_multiple_files=False,
            help=t.get("drag_drop_text", "Dateien hierher ziehen und ablegen oder durchsuchen")
        )

        st.header(t["settings_header"])
        use_llm = st.toggle(t["use_llm_toggle"], value=False)
        
        # Dokumentsprache ausw√§hlen
        if use_llm:
            document_languages = {
                "auto": t["auto_detect"],
                "de": "Deutsch",
                "en": "English",
                "fr": "Fran√ßais",
                "es": "Espa√±ol",
                "it": "Italiano",
                "nl": "Nederlands",
                "pt": "Portugu√™s",
                "ru": "–†—É—Å—Å–∫–∏–π",
                "zh": "‰∏≠Êñá",
                "ja": "Êó•Êú¨Ë™û"
            }
            
            doc_lang = st.selectbox(
                t["document_language"],
                options=list(document_languages.keys()),
                format_func=lambda x: document_languages[x],
                index=0,
                help=t["document_language_help"]
            )
        else:
            doc_lang = "auto"

        st.header(t["llm_provider_header"])
        llm_provider = st.radio(t["select_llm_provider"], ["Local", "OpenAI"], index=0)

        # Add configuration options for each provider
        custom_api_key = None
        local_llm_url = None
        
        if llm_provider == "OpenAI":
            custom_api_key = st.text_input(
                t["openai_api_key"],
                type="password",
                help=t["api_key_help"],
                value=os.getenv('OPENAI_API_KEY', '')
            )
        else:  # Local LLM
            local_llm_url = st.text_input(
                t["local_llm_url"],
                value="http://127.0.0.1:1234/v1/chat/completions",
                help=t["local_llm_help"]
            )

        if st.button(t["clear_cache"]):
            clear_cache()
            st.success(t["cache_cleared"])
        
        st.markdown(f"""
        ### {t["supported_formats"]}
        - PDF ({t.get("extract_images_text", "Extrahiert Text und Bilder und beschreibt Bilder inline, wenn LLM aktiviert ist")})
        - PPTX
        - DOCX
        - XLSX
        - Images
        - Audio
        - HTML
        - Text
        """)

    if uploaded_file:
        with st.spinner(t["processing"]):
            try:
                text_content = process_document(
                    uploaded_file, 
                    use_llm=use_llm, 
                    llm_provider=llm_provider, 
                    custom_api_key=custom_api_key,
                    local_llm_url=local_llm_url,
                    ui_lang=lang,
                    doc_lang=doc_lang
                )
                
                st.header(t["analysis_results"])
                tab1, tab2, tab3 = st.tabs([t["tab_extracted"], t["tab_info"], t["tab_debug"]])
                
                with tab1:
                    st.text_area(t["tab_extracted"], text_content, height=600)
                    st.download_button(
                        t["download_button"],
                        text_content,
                        file_name=f"{uploaded_file.name}_extracted.md",
                        mime="text/plain"
                    )
                
                with tab2:
                    st.json({
                        "Filename": uploaded_file.name,
                        "File size (KB)": f"{uploaded_file.size / 1024:.2f}",
                        "File type": uploaded_file.type
                    })
                
                with tab3:
                    if debug_logs:
                        st.write(t["debug_logs_title"])
                        for log in debug_logs:
                            st.write(log)
                    else:
                        st.write(t["no_debug_logs"])
            except Exception as e:
                st.error(f"{t['error_processing']} {str(e)}")
                if debug_logs:
                    st.write(t["debug_logs_title"])
                    for log in debug_logs:
                        st.write(log)
    else:
        st.info(t["upload_prompt"])

if __name__ == "__main__":
    main()
